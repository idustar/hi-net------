webpackJsonp([18],{740:function(e,t,a){"use strict";function n(e){return e&&e.__esModule?e:{default:e}}Object.defineProperty(t,"__esModule",{value:!0});var r=a(776),s=n(r),i=a(16),o=n(i),d=a(183),l=n(d),u=a(321),c=n(u),p=a(307),f=n(p);a(308);var h=a(299),y=a(185);t.default={namespace:"model",state:{globalVariable:{iteration:1,lr:.01,l2:.002},list:[],loading:!1,model:{},epochs:void 0,batchSize:void 0,self_datasets:[],datasets:[{id:11,type:"conv",dataset:"mnist",name:"MNIST",amount:6e4,description:"consists of images of handwritten digits. \nMNIST is a classic problem in machine learning. The problem is to look at greyscale 28x28 pixel images of handwritten digits and determine which digit the image represents, for all the digits from zero to nine."},{id:1,type:"dense",dataset:"iris",name:"Iris",amount:100,description:"This is perhaps the best known database to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant."},{id:2,type:"conv",dataset:"cifar",name:"Cifar-10",amount:5e4,description:"The CIFAR-10 dataset consists of 60000 32x32 color images in 10 classes, with 6000 images per class."},{id:3,type:"conv",dataset:"emnist-complete",name:"EMNIST ByClass",amount:697932,description:"814,255 characters, and 62 unbalanced classes."},{id:4,type:"conv",dataset:"emnist-merge",name:"EMNIST ByMerge",amount:697932,description:"814,255 characters, and 47 unbalanced classes."},{id:5,type:"conv",dataset:"emnist-balance",name:"EMNIST Balanced",amount:112800,description:"131,600 characters, and 47 balanced classes."},{id:6,type:"conv",dataset:"emnist-letter",name:"EMNIST Letters",amount:88800,description:"1145,600 characters, and 26 balanced classes."},{id:7,type:"conv",dataset:"emnist-digits",name:"EMNIST Digits",amount:24e4,description:"280,000 characters, and 10 balanced classes."},{id:8,type:"conv",dataset:"emnist-mnist",name:"EMNIST MNIST",amount:6e4,description:"70,000 characters, and 10 balanced classes."},{id:9,type:"rnn",amount:54e3,dataset:"shakespeare",name:"Shakespeare",description:"Complete Works of William Shakespeare\nfrom Project Gutenberg"}],layers:[{layerId:0,type:"convolution",ctype:"Convolution Layer",filters:5,kernelSize:3,strides:2,padding:0,activation:"relu",desc:"Convolution layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume.\n\nactivation function: will apply an element-wise activation function, such as the max(0,x) thresholding at zero\nfilters: each learning to look for something different in the input.\nstride:\xa0the way slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.\npadding: pad the input volume with zeros around the border.\nkernel size: specify the length of the convolution window\xa0"},{type:"dense",layerId:1,ctype:"Dense Layer",outputDim:200,activation:"relu",weightInit:"xavier",desc:"each neuron in this layer will be connected to all the numbers in the previous volume\n\nit performs the following calculation\noutput = activation(dot(input, weights)+bias)\n\nweight initialization: method of initializing the weights\noutput dimension: specify the output dimensions of the layer\nactivation: performs element-wise calculation of the output"},{layerId:2,type:"pooling",ctype:"Pooling Layer",kernelSize:2,strides:2,poolingType:"max",desc:"POOL layer will perform a downsampling operation along the spatial dimensions (width, height), it progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting.\nkernel size: \xa0size of the pooling windows\nstrides: downsampling factor\npooling type:\nmax: max pooling operation for spatial data"},{layerId:3,type:"dropout",ctype:"Dropout Layer",dropoutRate:.5,desc:"randomly setting a fraction rate\xa0of input units to 0 at each update during training time, which helps prevent overfitting.\n\ndropout rate: float between 0 and 1. Fraction of the input units to drop."},{layerId:4,ctype:"Output Layer",type:"output",outputNum:2,activation:"softmax",lossFunction:"neg",desc:"For output"},{layerId:5,ctype:"LSTM Layer",type:"lstm",desc:"hidden layer width: number of units in each LSTM layer\nhidden layer depth: number of hidden layers\nsequence length: Length of input sequences",hiddenLayerWidth:200,hiddenLayerCount:3,sequenceLen:200}],cards:[]},effects:{save:l.default.mark(function e(t,a){var n,r,s,i,o,d,u,p=a.call,y=(a.put,a.select);return l.default.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,y(function(e){return e.model.cards});case 2:return n=e.sent,e.next=5,y(function(e){return e.model.model});case 5:return r=e.sent,e.next=8,y(function(e){return e.model.globalVariable});case 8:if(s=e.sent,r.datasetId){e.next=12;break}return f.default.error({message:"save failed!",description:"no dataset selected."}),e.abrupt("return");case 12:if(i=n.filter(function(e){return 4===e.layerId}),0!==i.length){e.next=18;break}return f.default.error({message:"Layers are invalid!",description:"An output layer is required!"}),e.abrupt("return");case 18:if(!(i.length>1)){e.next=23;break}return f.default.error({message:"Layers are invalid!",description:"Only one output layer in a model!"}),e.abrupt("return");case 23:if(4===n[n.length-1].layerId){e.next=28;break}return f.default.error({message:"Layers are invalid!",description:"The output layer is not the last layer!"}),e.abrupt("return");case 28:if(1!==n.length){e.next=33;break}return f.default.error({message:"Layers are invalid!",description:"You must add layers except output layer!"}),e.abrupt("return");case 33:if(!(n.length>12)){e.next=36;break}return f.default.warning({message:"Layers are invalid!",description:"only VIP users can add so many layers!"}),e.abrupt("return");case 36:return o={userid:parseInt(localStorage.getItem("id"),10),dataset:r.datasetName,layers:n,globalVariable:s},d={id:parseInt(r.id,10),name:r.name,type:r.datasetType,config:(0,c.default)(o),datasetId:r.datasetId,datasetName:r.datasetName},e.next=40,p(h.saveModel,d);case 40:u=e.sent,200===u.code?f.default.success({message:"saved!"}):f.default.error({message:"save failed!"});case 42:case"end":return e.stop()}},e,this)}),dealCard:l.default.mark(function e(t,a){var n=t.payload,r=(a.call,a.put);return l.default.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,r({type:n.type,payload:n});case 2:case"end":return e.stop()}},e,this)}),run:l.default.mark(function e(t,a){var n=t.payload,r=(a.call,a.put);return l.default.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,r({type:"setRunConfig",payload:n});case 2:case"end":return e.stop()}},e,this)}),fetch:l.default.mark(function e(t,a){var n,r=t.payload,s=a.call,i=a.put;return l.default.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,i({type:"changeLoading",payload:!0});case 2:return e.next=4,s(h.queryModelById,r);case 4:if(n=e.sent,n.code&&200===n.code){e.next=10;break}return e.next=8,i(y.routerRedux.push("/404"));case 8:e.next=12;break;case 10:return e.next=12,i({type:"queryModel",payload:n.result});case 12:return e.next=14,i({type:"changeLoading",payload:!1});case 14:case"end":return e.stop()}},e,this)}),fetchDatasets:l.default.mark(function e(t,a){var n,r=(t.payload,a.call),s=a.put;return l.default.wrap(function(e){for(;;)switch(e.prev=e.next){case 0:return e.next=2,s({type:"changeLoading",payload:!0});case 2:return e.next=4,r(h.queryDatasets);case 4:if(n=e.sent,n.code&&200===n.code){e.next=10;break}return e.next=8,s(y.routerRedux.push("/404"));case 8:e.next=12;break;case 10:return e.next=12,s({type:"saveDatasets",payload:Array.isArray(n.result)?n.result:[]});case 12:return e.next=14,s({type:"changeLoading",payload:!1});case 14:case"end":return e.stop()}},e,this)})},reducers:{refreshCards:function(e,t){var a=t.payload;return(0,o.default)({},e,{cards:a})},reverseCardAttr:function(e,t){var a=t.payload,n=a.id,r=a.values,i=[].concat((0,s.default)(e.cards)),d=i.findIndex(function(e){return e.id===n});return console.log("index",d),d>=0&&(i[d]=(0,o.default)({},i[d],r)),(0,o.default)({},e,{cards:i})},saveDatasetId:function(e,t){var a=t.payload;return a?(0,o.default)({},e,{cards:[],model:(0,o.default)({},e.model,{datasetId:a,datasetName:e.datasets.find(function(e){return e.id===a}).dataset,datasetType:e.datasets.find(function(e){return e.id===a}).type})}):(0,o.default)({},e,{cards:[],model:(0,o.default)({},e.model,{datasetId:null,datasetName:null,datasetType:null})})},saveDatasets:function(e,t){var a=t.payload;return(0,o.default)({},e,{self_datasets:a})},queryModel:function(e,t){var a=t.payload;if(a.config){var n=JSON.parse(a.config||{});a.datasetName=n&&n.dataset?n.dataset:null,console.log(a.datasetName),a.datasetId=a.datasetName?e.datasets.find(function(e){return e.dataset===a.datasetName}).id:null,a.datasetType=a.datasetId?e.datasets.find(function(e){return e.id===a.datasetId}).type:null;var r=Array.isArray(n.layers)?n.layers:[],s=n.globalVariable||{};return(0,o.default)({},e,{model:a,globalVariable:s,cards:r})}a.datasetId=null;var i=[],d={l2:0,lr:0,iteration:0};return(0,o.default)({},e,{model:a,globalVariable:d,cards:i})},appendList:function(e,t){return(0,o.default)({},e,{list:e.list.concat(t.payload)})},setRunConfig:function(e,t){var a=t.payload;return(0,o.default)({},e,{epochs:a.epochs,batchSize:a.batchSize})},changeLoading:function(e,t){return(0,o.default)({},e,{loading:t.payload})},changeGlobalVariable:function(e,t){var a=t.payload,n=a.key,r=a.value,s=(0,o.default)({},e.globalVariable);return s[n]=r,(0,o.default)({},e,{globalVariable:s})}}},e.exports=t.default},776:function(e,t,a){"use strict";t.__esModule=!0;var n=a(810),r=function(e){return e&&e.__esModule?e:{default:e}}(n);t.default=function(e){if(Array.isArray(e)){for(var t=0,a=Array(e.length);t<e.length;t++)a[t]=e[t];return a}return(0,r.default)(e)}},810:function(e,t,a){e.exports={default:a(302),__esModule:!0}}});